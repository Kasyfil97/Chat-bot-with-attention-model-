{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import csv\n",
    "#from nltk import word_tokenize\n",
    "#from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load file\n",
    "convs=open('movie_conversations.txt').read()\n",
    "lines=open('movie_lines.txt',encoding='utf-8',errors='ignore').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversation has been exported\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['L3490', 'L3491', 'L3492', 'L3493']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a list of all of the conversations' lines' ids.\n",
    "\n",
    "convers=[]\n",
    "for conv in convs.split('\\n'):\n",
    "    _conv=conv.split('+++$+++')[-1][2:-1].replace(\"'\",\"\").replace(\",\",\"\")\n",
    "    convers.append(_conv.split())\n",
    "\n",
    "print('conversation has been exported')\n",
    "convers[300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' They do not!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary to map each line's id with its text\n",
    "idline={}\n",
    "for line in lines.split('\\n'):\n",
    "    _line=line.split('+++$+++')\n",
    "    id=_line[0].replace(\" \",\"\")\n",
    "    idline[id]=_line[-1]\n",
    "idline['L1045']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221616\n"
     ]
    }
   ],
   "source": [
    "#making list of questions as input and answers as target\n",
    "\n",
    "data_array=[]\n",
    "for conv in convers:\n",
    "    for i in range(len(conv)-1):\n",
    "        convs=idline[conv[i]]\n",
    "        data_array.append(convs)\n",
    "\n",
    "print(len(data_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create cleaning and shorting function\n",
    "def cleaning(data):\n",
    "    '''clean data and fix the text from slank and shorten text\n",
    "    input : data as array from input or target\n",
    "    outpuy: cleaned array '''\n",
    "    data_temp=[]\n",
    "    for text in data:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"i'm\", \"i am\", text)\n",
    "        text = re.sub(r\"he's\", \"he is\", text)\n",
    "        text = re.sub(r\"she's\", \"she is\", text)\n",
    "        text = re.sub(r\"it's\", \"it is\", text)\n",
    "        text = re.sub(r\"that's\", \"that is\", text)\n",
    "        text = re.sub(r\"what's\", \"that is\", text)\n",
    "        text = re.sub(r\"where's\", \"where is\", text)\n",
    "        text = re.sub(r\"how's\", \"how is\", text)\n",
    "        text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "        text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"\\'d\", \" would\", text)\n",
    "        text = re.sub(r\"\\'re\", \" are\", text)\n",
    "        text = re.sub(r\"won't\", \"will not\", text)\n",
    "        text = re.sub(r\"can't\", \"cannot\", text)\n",
    "        text = re.sub(r\"n't\", \" not\", text)\n",
    "        text = re.sub(r\"n'\", \"ng\", text)\n",
    "        text = re.sub(r\"'bout\", \"about\", text)\n",
    "        text = re.sub(r\"'til\", \"until\", text)\n",
    "        text = re.sub(r\"[-()\\\"#/@;:<>{}`+=~|.!?,]\", \"\", text)\n",
    "        text = \" \".join(text.split())\n",
    "        data_temp.append(text)\n",
    "    return data_temp\n",
    "\n",
    "def shorting(data):\n",
    "    '''shorting the text and allow 2-20 lenght text\n",
    "    input: data from input and target\n",
    "    output: array'''\n",
    "    # Remove questions and answers that are shorter than 1 word and longer than 20 words.\n",
    "    min_line_length = 2\n",
    "    max_line_length = 20\n",
    "\n",
    "    # Filter out the answers that are too short/long\n",
    "    short_data = []\n",
    "\n",
    "    for text in data:\n",
    "        if len(text.split()) >= min_line_length and len(text.split()) <= max_line_length:\n",
    "            short_data.append(text)\n",
    "    return short_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(176516, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well i thought we would start with pronunciati...</td>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>not the hacking and gagging and spitting part ...</td>\n",
       "      <td>you are asking me out that is so cute that is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>you are asking me out that is so cute that is ...</td>\n",
       "      <td>no no it is my fault we did not have a proper ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no no it is my fault we did not have a proper ...</td>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gosh if only we could find kat a boyfriend</td>\n",
       "      <td>c'esc ma tete this is my head</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           questions  \\\n",
       "0  well i thought we would start with pronunciati...   \n",
       "1  not the hacking and gagging and spitting part ...   \n",
       "2  you are asking me out that is so cute that is ...   \n",
       "3  no no it is my fault we did not have a proper ...   \n",
       "4         gosh if only we could find kat a boyfriend   \n",
       "\n",
       "                                             answers  \n",
       "0  not the hacking and gagging and spitting part ...  \n",
       "1  you are asking me out that is so cute that is ...  \n",
       "2  no no it is my fault we did not have a proper ...  \n",
       "3         gosh if only we could find kat a boyfriend  \n",
       "4                      c'esc ma tete this is my head  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cleaning\n",
    "data_array=cleaning(data_array)\n",
    "\n",
    "#shorting\n",
    "data_array=shorting(data_array)\n",
    "len(data_array)\n",
    "\n",
    "# Sort the sentences into questions (inputs) and answers (targets)\n",
    "questions = [] # input\n",
    "answers = [] #target\n",
    "for i in range(len(data_array)-1):\n",
    "    questions.append(data_array[i])\n",
    "    answers.append(data_array[i+1])\n",
    "\n",
    "_data={'questions':questions,'answers':answers}\n",
    "data=pd.DataFrame(_data)\n",
    "print(data.shape)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dataframe as csv\n",
    "data.to_csv('cleaning_data.csv')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96469a127def15a62ded042fba5089068494d4d23c4c88339d0c2940f4c47e25"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
